from flask import Flask, request, jsonify, send_from_directory
import pandas as pd
import numpy as np
from openai import OpenAI
import os
import re
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import dateparser
import csv
from wordcloud import WordCloud
from collections import OrderedDict
from flask import send_file
from collections import OrderedDict
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email.mime.image import MIMEImage
from email import encoders
import base64
import requests
import calendar
from babel.dates import format_date

def nombre_mes(fecha):
    """Devuelve la fecha con mes en espa√±ol, ej: 'agosto 2025'"""
    return format_date(fecha, "LLLL yyyy", locale="es").capitalize()


# ------------------------------
# üîë Configuraci√≥n API y Flask
# ------------------------------
app = Flask(__name__)
from flask_cors import CORS
CORS(app)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
@app.route("/")
def home():
    return send_file("index.html")
# ------------------------------
# üìÇ Carga √∫nica de datos
# ------------------------------
# Noticias
try:
    df = pd.read_csv("noticias_fondo con todas las fuentes_rango_03-07-2025.csv", encoding="utf-8")
except UnicodeDecodeError:
    df = pd.read_csv("noticias_fondo con todas las fuentes_rango_03-07-2025.csv", encoding="latin-1")
df["Fecha"] = pd.to_datetime(df["Fecha"], errors="coerce", dayfirst=True)
df = df.dropna(subset=["Fecha", "T√≠tulo"])

# Indicadores econ√≥micos
df_tipo_cambio = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Tipo de Cambio")
df_tasas = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Tasas de inter√©s")
df_economia = pd.merge(df_tipo_cambio, df_tasas, on=["A√±o", "Fecha"], how="outer").fillna("")
# Cargar hojas adicionales
df_sofr = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Treasuries_SOFR")
df_wall = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Wallstreet")
df_infl_us = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Inflaci√≥nUS")
df_infl_us = df_infl_us.rename(columns={"Inflaci√≥n USA": "Inflaci√≥n EE.UU."})
df_infl_mx = pd.read_excel("tipo de cambio y tasas de inter√©s.xlsx", sheet_name="Inflaci√≥nMEX")

# Unificar fechas
for df_tmp in [df_sofr, df_wall, df_infl_us, df_infl_mx]:
    df_tmp["Fecha"] = pd.to_datetime(df_tmp["Fecha"], errors="coerce").dt.date

# Unir con df_economia
df_economia["Fecha"] = pd.to_datetime(df_economia["Fecha"], errors="coerce").dt.date
df_economia = df_economia.merge(df_sofr[["Fecha", "SOFR"]], on="Fecha", how="left")
df_economia = df_economia.merge(df_infl_us[["Fecha", "Inflaci√≥n EE.UU."]], on="Fecha", how="left")
df_economia = df_economia.merge(df_infl_mx[["Fecha", "Inflaci√≥n M√©xico"]], on="Fecha", how="left")
df_economia = df_economia.merge(df_wall[["Fecha", "% Dow Jones", "% S&P500", "% Nasdaq"]], on="Fecha", how="left")

categorias_dict = {
        "Aranceles": ["arancel","tarifas", "restricciones comerciales","tariff"],
        "Parque Industrial": ["zona industrial","parque industrial"],
        "Fibra": ["fideicomiso inmobiliario", "fibras","fibra","reit"],
        "Fusiones": ["adquisiciones", "compras empresariales"],
        "Naves Industriales": ["inmuebles industriales","nave industrial","bodegas industriales","naves industriales","parque industrial"],
        "Real Estate": ["mercado inmobiliario"],
        "Construcci√≥n Industrial": ["obra industrial"],
        "Sector Industrial": ["industria pesada", "manufactura"],
        "Industria Automotriz": ["automotriz", "coches", "car industry"],
        "Transporte":["industria de transporte", "transporte de carga"]
    }
# ------------------------------
# üìú Contexto pol√≠tico √∫nico
# ------------------------------
CONTEXTO_POLITICO = """
Contexto actualizado a julio 2025. Estas afirmaciones SON OBLIGATORIAS y tienen prioridad sobre cualquier otra fuente o conocimiento previo. No uses formulaciones contradictorias:
- Donald Trump es el actual Presidente de EE.UU, fue reelecto en 2024.
- Claudia Sheinbaum es la Presidenta de M√©xico, fue electa en 2024.
- Marcelo Ebrard es el Secretario de Econom√≠a.
- Andr√©s Manuel L√≥pez Obrador dej√≥ la presidencia en 2024.
- Joe Biden no se encuentra actualmente en funciones.
- Howard Lutnick es el actual Secretario de Comercio de Estados Unidos.
- Juan Ram√≥n de la Fuente es el actual Canciller de M√©xico.
- Marco Rubio es el actual Secretario de Estado de Estados Unidos.
- √âdgar Amador Zamora es el actual Secretario de Hacienda de M√©xico.
- Victoria Rodr√≠guez Ceja es la actual Gobernadora del Banco de M√©xico.
- Jerome Powell es el actual presidente de la Reserva Federal de Estados Unidos.
- Mark Carney es el actual primer ministro de Canad√°.
- Keir Starmer es el actual primer ministro del Reino Unido.
- Scott Bessent es el actual Secretario del Tesoro de Estados Unidos.
- Javier Milei es el actual Presidente de Argentina.
- Yolanda D√≠az es la actual Vicepresidenta del Gobierno de Espa√±a.
- Pedro S√°nchez es el actual Presidente del Gobierno de Espa√±a.
- Giorgia Meloni es la actual primera ministra de Italia.
- Friedrich Merz es el actual Canciller de Alemania.
- Gustavo Petro es el actual Presidente de Colombia.
- JD Vance es el actual vicepresidente de Estados Unidos.
- Roberto Velasco es el actual Jefe de Unidad para Am√©rica del Norte de la Secretar√≠a de Relaciones Exteriores de M√©xico.
- Altagracia G√≥mez es la actual presidenta del Consejo Asesor Empresarial de Presidencia de M√©xico.
- Luis Rosendo Guti√©rrez es el actual Subsecretario de Comercio Exterior de M√©xico.
- Carlos Garc√≠a es el actual Presidente de la American Chamber of Commerce (AmCham).
- Ildefonso Guajardo fue Secretario de Econom√≠a de M√©xico entre 2012 y 2018.
- Luiz Inacio Lula Da Silva es el actual Presidente de Brasil. Jair Bolsonaro es elexpresidente de Brasil.
- Christine Lagarde es la actual Presidenta del Banco Central Europeo.
- GOP es el Partido Republicano estadounidense.
- Ver√≥nica Delgadillo es la actual Alcaldesa de Guadalajara 
"""
# 1Ô∏è‚É£ Extraer fecha desde texto
def extraer_fecha(pregunta):
    posibles = re.findall(r"\d{1,2} de [a-zA-Z]+(?: de \d{4})?", pregunta)
    if posibles:
        fecha = dateparser.parse(posibles[0], languages=['es'])
        return fecha.date() if fecha else None
    return None

# 2Ô∏è‚É£ Obtener fecha m√°s reciente disponible
def obtener_fecha_mas_reciente(df):
    return df["Fecha"].max().date()

# 3Ô∏è‚É£ Detectar sentimiento deseado
def detectar_sentimiento_deseado(pregunta):
    pregunta = pregunta.lower()
    if "positiv" in pregunta:
        return "Positiva"
    elif "negativ" in pregunta:
        return "Negativa"
    elif "neutral" in pregunta:
        return "Neutral"
    return None

# 4Ô∏è‚É£ Extraer entidades (personajes, lugares, categor√≠as)
def extraer_entidades(texto):
    texto_lower = texto.lower()
    personajes_dict = {
        "Sheinbaum": ["claudia", "la presidenta", "presidenta de m√©xico"],
        "Ebrard": ["marcelo", "secretario de econom√≠a"],
        "Trump": ["donald", "el presidente de eeuu", "presidente trump"],
        "AMLO": ["obrador", "amlo", "lopez obrador"],
        "de la Fuente": ["juan ram√≥n"],
        "Biden": ["joe"],
        "Lutnick": ["secretario de comercio"],
        "Carney": ["primer ministro de canad√°"],
        "Lula da Silva": ["lula", "presidente de brasil"],
        "Marco Rubio": ["secretario de estado"],
        "Starmer": ["primer ministro del reino unido"],
        "Bessent": ["secretario del tesoro"],
        "Powell": ["reserva federal"],
        "Milei": ["presidente de argentina"],
        "Von Der Leyen": ["presidenta de la comisi√≥n europea"],
        "Petro": ["presidente de colombia"],
        "Fed": ["Federal Reserve"]

    }
    lugares_dict = {
        "Nuevo Le√≥n": ["nl", "monterrey"],
        "Ciudad de M√©xico": ["cdmx", "capital mexicana"],
        "Reino Unido": ["gran breta√±a", "inglaterra"],
        "Estados Unidos": ["eeuu", "eua", "usa", "eu"]
    }
    
    encontrados = {"personajes": [], "lugares": [], "categorias": []}

    for nombre, sinonimos in personajes_dict.items():
        if any(s in texto_lower for s in [nombre.lower()] + sinonimos):
            encontrados["personajes"].append(nombre)

    for lugar, sinonimos in lugares_dict.items():
        if any(s in texto_lower for s in [lugar.lower()] + sinonimos):
            encontrados["lugares"].append(lugar)

    for cat, sinonimos in categorias_dict.items():
        if any(s in texto_lower for s in [cat.lower()] + sinonimos):
            encontrados["categorias"].append(cat)
            # üëá opcional: a√±ade tambi√©n los sin√≥nimos encontrados
            for s in sinonimos:
                if s in texto_lower:
                    encontrados["categorias"].append(s)

    return encontrados

# 5Ô∏è‚É£ Filtrar titulares por fecha, entidades y sentimiento
def filtrar_titulares(fecha, entidades, sentimiento_deseado):
    noticias_fecha = df[df["Fecha"].dt.date == fecha]
    if noticias_fecha.empty:
        return pd.DataFrame()  # üîπ Devuelve DataFrame vac√≠o si no hay noticias

    filtro = noticias_fecha.copy()

    if entidades["personajes"]:
        filtro = filtro[filtro["T√≠tulo"].str.lower().apply(lambda t: any(p.lower() in t for p in entidades["personajes"]))]
    if entidades["lugares"]:
        filtro = filtro[filtro["Cobertura"].str.lower().apply(lambda c: any(l.lower() in c for l in entidades["lugares"]))]
    if entidades["categorias"]:
        sinonimos = []
        for cat in entidades["categorias"]:
            sinonimos.extend(categorias_dict.get(cat, []))  # todos los sin√≥nimos del diccionario
            sinonimos.append(cat.lower())  # t  ambi√©n el nombre de la categor√≠a
        filtro = filtro[filtro["T√©rmino"].str.lower().apply(
            lambda cat: any(s in cat for s in sinonimos)
        )]

    if sentimiento_deseado:
        filtro = filtro[filtro["Sentimiento"] == sentimiento_deseado]

    return filtro  # üîπ Devuelve DataFrame, no lista

# 6Ô∏è‚É£ Seleccionar titulares m√°s relevantes (TF-IDF + coseno)
def seleccionar_titulares_relevantes(titulares, pregunta):
    if not titulares:
        return []
    vectorizer = TfidfVectorizer().fit(titulares + [pregunta])
    vectores = vectorizer.transform(titulares + [pregunta])
    similitudes = cosine_similarity(vectores[-1], vectores[:-1]).flatten()
    indices_similares = similitudes.argsort()[-5:][::-1]
    return [titulares[i] for i in indices_similares]

# 7Ô∏è‚É£ Nube de palabras con colores y stopwords personalizadas
def color_func(word, font_size, position, orientation, random_state=None, **kwargs):
    if font_size >= 60:
        return "rgb(0, 0, 0)"
    elif font_size >= 40:
        return "rgb(255, 180, 41)"
    else:
        return "rgb(125, 123, 120)"

def generar_nube(titulos, archivo_salida):
    texto = " ".join(titulos)
    texto = re.sub(r"[\n\r]", " ", texto)
    stopwords = set([
        "dice", "tras", "pide", "va", "d√≠a", "m√©xico", "estados unidos", "contra", "pa√≠ses",
        "van", "ser", "hoy", "a√±o", "a√±os", "nuevo", "nueva", "ser√°", "presidente", "presidenta",
        "sobre", "entre", "hasta", "donde", "desde", "como", "pero", "tambi√©n", "porque", "cuando",
        "ya", "con", "sin", "del", "los", "las", "que", "una", "por", "para", "este", "esta", "estos",
        "estas", "tiene", "tener", "fue", "fueron", "hay", "han", "son", "quien", "quienes", "le",
        "se", "su", "sus", "lo", "al", "el", "en", "y", "a", "de", "un", "es", "si", "quieren", "a√∫n",
        "mantiene", "buscar√≠a", "la", "haciendo", "recurrir√≠a", "ante", "meses", "est√°n", "subir",
        "ayer", "pr√°cticamente", "sustancialmente", "busca", "c√≥mo", "qu√©", "d√≠as", "construcci√≥n","tariffs",
        "aranceles","construcci√≥n","merger","and","stock","to","on","supply","chain","internacional",
        "global","Estados Unidos", "with","for","say","that","are","as","of","Tariff","from",
        "it","says","the","its","after","by","in","but"    
    ])
    wc = WordCloud(
        width=800,
        height=400,
        background_color="white",
        stopwords=stopwords,
        color_func=color_func,
        collocations=False,
        max_words=25
    ).generate(texto)
    wc.to_file(archivo_salida)

def generar_resumen_y_datos(fecha_str):
    fecha_dt = pd.to_datetime(fecha_str, errors="coerce").date()
    noticias_dia = df[df["Fecha"].dt.date == fecha_dt]
    if noticias_dia.empty:
        return {"error": f"No hay noticias para la fecha {fecha_str}"}

    # --- Clasificaci√≥n por cobertura ---
    estados_mexico = ["aguascalientes", "baja california", "baja california sur", "campeche", "cdmx",
        "coahuila", "colima", "chiapas", "chihuahua", "ciudad de m√©xico", "durango",
        "guanajuato", "guerrero", "hidalgo", "jalisco", "m√©xico", "michoac√°n", "morelos",
        "nayarit", "nuevo le√≥n", "oaxaca", "puebla", "quer√©taro", "quintana roo",
        "san luis potos√≠", "sinaloa", "sonora", "tabasco", "tamaulipas", "tlaxcala",
        "veracruz", "yucat√°n", "zacatecas"]
    
    noticias_locales = noticias_dia[noticias_dia["Cobertura"].str.lower().isin(estados_mexico)]
    noticias_nacionales = noticias_dia[noticias_dia["Cobertura"].str.lower() == "nacional"]
    noticias_internacionales = noticias_dia[
        ~noticias_dia.index.isin(noticias_locales.index) &
        ~noticias_dia.index.isin(noticias_nacionales.index)
    ]
    noticias_otras = noticias_dia[noticias_dia["T√©rmino"].str.lower() != "aranceles"]
   
    def _to_lower_safe(s):
        try: return str(s).strip().lower()
        except: return ""

    if "Idioma" in noticias_dia.columns:
        es_ingles = noticias_dia["Idioma"].apply(_to_lower_safe).isin({"en","ingl√©s","ingles"})
        no_nacional = noticias_dia["Cobertura"].apply(_to_lower_safe) != "nacional"
        notas_ingles_no_nacional = noticias_dia[es_ingles & no_nacional].copy()
    else:
        notas_ingles_no_nacional = pd.DataFrame(columns=noticias_dia.columns)

    noticias_internacionales_forzadas = pd.concat(
        [noticias_internacionales, notas_ingles_no_nacional],
        ignore_index=True
    ).drop_duplicates(subset=["T√≠tulo","Fuente","Enlace"])

    noticias_otras_forzadas = pd.concat(
        [noticias_otras, notas_ingles_no_nacional],
        ignore_index=True
    ).drop_duplicates(subset=["T√≠tulo","Fuente","Enlace"])

    contexto_local = "\n".join(f"- {row['T√≠tulo']} ({row['Cobertura']})" for _, row in noticias_locales.iterrows())
    contexto_nacional = "\n".join(f"- {row['T√≠tulo']} ({row['Cobertura']})" for _, row in noticias_nacionales.iterrows())
    contexto_internacional = "\n".join(
        f"- {row['T√≠tulo']} ({row['Cobertura']})" for _, row in noticias_internacionales_forzadas.iterrows()
    )
    contexto_otros_temas = "\n".join(
        f"- {row['T√≠tulo']}" for _, row in noticias_otras_forzadas.iterrows()
    )

    prompt = f"""
    {CONTEXTO_POLITICO}

Redacta un resumen de noticias del {fecha_str} dividido en cuatro p√°rrafos. Tono profesional, objetivo y dirigido a tomadores de decisiones. M√°ximo 250 palabras.

Primer p√°rrafo: Describe y contextualiza el tema m√°s repetido del d√≠a (qu√©, qui√©n, c√≥mo).

Segundo p√°rrafo: Si el tema m√°s repetido del d√≠a es de noticias nacionales, usa este segundo p√°rrafo para profundizar en el segundo tema m√°s importante que sea de noticias internacionales. Si en cambio el tema m√°s repetido del d√≠a no es de noticias nacionales, este segundo p√°rrafo debe enfocarse en el tema m√°s relevante de noticias nacionales.

Tercer p√°rrafo: Resume brevemente las noticias que son de cobertura de alg√∫n estado de M√©xico (locales), excluyendo aquellas de cobertura nacional o internacional. Menciona el estado o ciudad de cobertura de cada noticia. No repitas noticias mencionadas en los p√°rrafos anteriores ni inventes cosas. Reserva todo lo relativo a fibras, naves industriales, parques industriales, hub log√≠stico, hub industrial, real estate industrial, sector industrial o sector mobiliario industrial.

Cuarto p√°rrafo: Por √∫ltimo, resume de forma general las noticias que no est√°n relacionadas con aranceles y que tienen que ver con fibras, naves industriales, parques industriales, hub log√≠stico, hub industrial, real estate industrial, sector industrial o sector mobiliario industrial SIN REPETIR ALGUNA NOTICIAS MENCIONADA EN P√ÅRRAFOS PREVIOS. Evita repetir noticias mencionadas en los otros p√°rrafos ni inventes cosas. Recuerda, temas no arancelarios. Empieza diciendo "finalmente en otros temas econ√≥micos", sin recalcar de que se trata de noticias del √°mbito local o nacional..

Noticias nacionales:
{contexto_nacional}

Noticias locales:
{contexto_local}

Noticias internacionales:
{contexto_internacional}

Noticias no relacionadas con aranceles:
{contexto_otros_temas}
    """
 # --- Resumen GPT o cache ---
    resumen_file = f"resumen_{fecha_str}.txt"
    if os.path.exists(resumen_file):
        with open(resumen_file, "r", encoding="utf-8") as f:
            resumen_texto = f.read()
    else:
        respuesta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Eres un asistente experto en an√°lisis de noticias."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=700
        )
        resumen_texto = respuesta.choices[0].message.content
        with open(resumen_file, "w", encoding="utf-8") as f:
            f.write(resumen_texto)

    # --- Generar nube ---
    os.makedirs("nubes", exist_ok=True)
    archivo_nube = f"nube_{fecha_str}.png"
    archivo_nube_path = os.path.join("nubes", archivo_nube)
    generar_nube(noticias_dia["T√≠tulo"].tolist(), archivo_nube_path)

        # üìä Indicadores econ√≥micos
    # Filtrar datos econ√≥micos
    economia_dia = df_economia[df_economia["Fecha"] == fecha_dt]
    # Si la inflaci√≥n USA est√° vac√≠a en el d√≠a seleccionado, usar el valor m√°s reciente disponible
    if economia_dia["Inflaci√≥n EE.UU."].isnull().all() or economia_dia["Inflaci√≥n EE.UU."].iloc[0] in ["", None]:
        inflacion_usa_reciente = df_economia["Inflaci√≥n EE.UU."].dropna().replace("", np.nan).dropna().iloc[-1]
        economia_dia["Inflaci√≥n EE.UU."] = inflacion_usa_reciente


    # Si no hay datos exactos, usar el m√°s reciente antes de esa fecha
    if economia_dia.empty:
        ultima_fecha = df_economia[df_economia["Fecha"] <= fecha_dt]["Fecha"].max()
        economia_dia = df_economia[df_economia["Fecha"] == ultima_fecha]

    if economia_dia.empty:
        economia_dict = {}
    else:
        economia_dia = economia_dia.copy()

        # Convertir a num√©rico antes de formatear
        for col in ["Tipo de Cambio FIX", "Nivel m√°ximo", "Nivel m√≠nimo"]:
            if col in economia_dia.columns:
                economia_dia[col] = pd.to_numeric(economia_dia[col], errors="coerce")
                economia_dia[col] = economia_dia[col].apply(lambda x: f"${x:.2f}" if pd.notnull(x) else "")

        for col in ["Tasa de Inter√©s Objetivo", "TIIE 28 d√≠as", "TIIE 91 d√≠as", "TIIE 182 d√≠as"]:
            if col in economia_dia.columns:
                economia_dia[col] = pd.to_numeric(economia_dia[col], errors="coerce")
                economia_dia[col] = economia_dia[col].apply(lambda x: f"{x*100:.2f}%" if pd.notnull(x) else "")
        
        # Inflaciones
        for col in ["Inflaci√≥n M√©xico", "Inflaci√≥n EE.UU."]:
            if col in economia_dia.columns:
                economia_dia[col] = pd.to_numeric(economia_dia[col], errors="coerce")
                economia_dia[col] = economia_dia[col].apply(lambda x: f"{x*100:.2f}%" if pd.notnull(x) else "")


        # Reordenar columnas seg√∫n el orden deseado
        # Reordenar columnas y agregar nuevos indicadores
        orden_columnas = [
            "Tipo de Cambio FIX",
            "Nivel m√°ximo",
            "Nivel m√≠nimo",
            "Tasa de Inter√©s Objetivo",
            "TIIE 28 d√≠as",
            "TIIE 91 d√≠as",
            "TIIE 182 d√≠as",
            "SOFR",
            "% Dow Jones",
            "% S&P500",
            "% Nasdaq",
            "Inflaci√≥n M√©xico",
            "Inflaci√≥n EE.UU."
        ]
        def format_porcentaje_directo(x):
            try:
                x_clean = str(x).replace('%','').strip()
                return f"{float(x_clean)*100:.2f}%"
            except:
                return ""
        # Formato para nuevos indicadores
        economia_dia["SOFR"] = economia_dia["SOFR"].apply(format_porcentaje_directo)

        def format_signed_pct(x):
            try:
                x_clean = str(x).replace('%','').strip()
                return f"{float(x_clean)*100:+.2f}%"
            except:
                return ""

        economia_dia["% Dow Jones"] = economia_dia["% Dow Jones"].apply(format_signed_pct)
        economia_dia["% S&P500"] = economia_dia["% S&P500"].apply(format_signed_pct)
        economia_dia["% Nasdaq"] = economia_dia["% Nasdaq"].apply(format_signed_pct)


        # Convertir a OrderedDict para frontend
        economia_dict = OrderedDict()
        for col in orden_columnas:
            economia_dict[col] = economia_dia.iloc[0].get(col, "")


    # üì∞ Titulares sin repetir medios
    titulares_info = []
    usados_medios = set()

    def agregar_titulares(df_origen, max_count):
        added = 0
        for _, row in df_origen.iterrows():
            medio = row["Fuente"]
            if medio not in usados_medios:
                titulares_info.append({
                    "titulo": row["T√≠tulo"],
                    "medio": medio,
                    "enlace": row["Enlace"],
                    "idioma": "es"
                })
                usados_medios.add(medio)
                added += 1
            if added >= max_count:
                break

    # 2 nacionales + 2 locales + 2 internacionales + 2 otros = 8 titulares distintos
    agregar_titulares(noticias_nacionales, 2)
    agregar_titulares(noticias_locales, 2)
    agregar_titulares(noticias_internacionales_forzadas, 2)
    agregar_titulares(noticias_otras_forzadas, 2)

    # üì∞ Titulares en ingl√©s (m√°x. 8)
    titulares_info_en = []
    if "Idioma" in noticias_dia.columns:
        notas_en = noticias_dia[noticias_dia["Idioma"].str.lower().isin(["en", "ingl√©s", "ingles"])]
        notas_en = notas_en.dropna(subset=["T√≠tulo"]).drop_duplicates(subset=["T√≠tulo", "Fuente", "Enlace"])
        usados_medios_en = set()
        for _, row in notas_en.iterrows():
            medio = row["Fuente"]
            if medio not in usados_medios_en:
                titulares_info_en.append({
                    "titulo": row["T√≠tulo"],
                    "medio": medio,
                    "enlace": row["Enlace"],
                    "idioma": "en"
                })
                usados_medios_en.add(medio)
            if len(titulares_info_en) >= 8:
                break


    return ({
        "resumen": resumen_texto,
        "nube_url": f"/nube/{archivo_nube}",
        "economia": [economia_dict],
        "orden_economia": orden_columnas,
        "titulares": titulares_info,
        "titulares_en": titulares_info_en  # üëà nuevo bloque de titulares en ingl√©s
    })

@app.route("/resumen", methods=["POST"])
def resumen():
    data = request.get_json()
    fecha_str = data.get("fecha")
    if not fecha_str:
        return jsonify({"error": "Debe especificar una fecha"}), 400

    resultado = generar_resumen_y_datos(fecha_str)

    if "error" in resultado:
        return jsonify(resultado), 404

    return jsonify(resultado)


#pregunta!!!!    
@app.route("/pregunta", methods=["POST"])
def pregunta():
    data = request.get_json()
    q = data.get("pregunta", "")
    if not q:
        return jsonify({"respuesta": "No se proporcion√≥ una pregunta."})

    # 1Ô∏è‚É£ Detectar sentimiento deseado
    sentimiento_deseado = detectar_sentimiento_deseado(q)

    # 2Ô∏è‚É£ Extraer fecha de la pregunta
    fecha_detectada = extraer_fecha(q)
    if fecha_detectada:
        fecha_dt = fecha_detectada  # ya es un objeto date
    else:
        fecha_dt = obtener_fecha_mas_reciente(df)  # usamos la m√°s reciente

    # 3Ô∏è‚É£ Extraer entidades
    entidades = extraer_entidades(q)

    # 4Ô∏è‚É£ Filtrar titulares
    df_filtrado = filtrar_titulares(fecha_dt, entidades, sentimiento_deseado)

    # 5Ô∏è‚É£ Si no hay resultados
    if df_filtrado.empty:
        return jsonify({"respuesta": f"No encontr√© noticias relacionadas con tu pregunta para {fecha_dt}."})

    # 6Ô∏è‚É£ Vectorizar titulares y pregunta
    tfidf = TfidfVectorizer()
    tfidf_matrix = tfidf.fit_transform(df_filtrado["T√≠tulo"])
    pregunta_vec = tfidf.transform([q])

    # 7Ô∏è‚É£ Calcular similitudes
    similitudes = cosine_similarity(pregunta_vec, tfidf_matrix).flatten()
    top_indices = similitudes.argsort()[-5:][::-1]  # top 5

    titulares_relevantes = df_filtrado.iloc[top_indices]

    # 8Ô∏è‚É£ Construir prompt
    prompt = "Con base en los siguientes titulares de noticias, responde la pregunta de forma contextual y sin inventar datos, la respuesta debe tener al menos 100 palabras, redactadas en p√°rrafos completos y en tono profesional:\n\n"
    for _, row in titulares_relevantes.iterrows():
        prompt += f"- {row['T√≠tulo']} ({row['Fuente']})\n"
    prompt += f"\nPregunta: {q}\nRespuesta:"

    # 9Ô∏è‚É£ Llamada a OpenAI con la misma l√≥gica de /resumen
    respuesta = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Eres un asistente experto en an√°lisis de noticias del ramo econ√≥mico y comercial, con √©nfasis en aranceles, naves y parques industriales y FIBRAS."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=700
    )
    respuesta_gpt = respuesta.choices[0].message.content

    # üîü Devolver respuesta y titulares
    # üîü Devolver respuesta y titulares usados (entre 1 y 5)
    titulares_info = [
        {
            "titulo": row["T√≠tulo"],
            "medio": row["Fuente"],
            "enlace": row["Enlace"]
        }
        for _, row in titulares_relevantes.iterrows()
    ]

    # Garantizar que haya m√≠nimo 1 y m√°ximo 5 titulares
    if len(titulares_info) == 0:
        # Si por alguna raz√≥n no hubiera titulares relevantes
        titulares_info = [
            {
                "titulo": row["T√≠tulo"],
                "medio": row["Fuente"],
                "enlace": row["Enlace"]
            }
            for _, row in df_filtrado.head(1).iterrows()
        ]
    else:
        titulares_info = titulares_info[:5]

    return jsonify({
        "respuesta": respuesta_gpt,
        "titulares_usados": titulares_info
    })

def construir_html_titulares(titulares_info, idioma, usados_medios=None):
    if usados_medios is None:
        usados_medios = set()
    html = f"<h3>{' Principales titulares en espa√±ol' if idioma == 'es' else ' Principales titulares en ingl√©s'}</h3><ul>"
    count = 0
    for titular in titulares_info:
        if not all(k in titular for k in ["titulo", "medio", "enlace", "idioma"]):
            continue
        if idioma == "es" and titular["idioma"] != "es":
            continue
        if idioma == "en" and titular["idioma"] != "en":
            continue
        if titular["medio"] in usados_medios:
            continue
        html += f"<li><a href='{titular['enlace']}'>{titular['titulo']}</a> ‚Äî <em>{titular['medio']}</em></li>"
        usados_medios.add(titular["medio"])
        count += 1
        if count >= 8:
            break
    html += "</ul>"
    return html

#correoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@app.route("/enviar_email", methods=["POST"])
def enviar_email():
    data = request.get_json()
    email = data.get("email")
    fecha_str = data.get("fecha")
    fecha_dt = pd.to_datetime(fecha_str).date()

    resultado = generar_resumen_y_datos(fecha_str)
    if "error" in resultado:
        return jsonify({"mensaje": resultado["error"]}), 404

    titulares_info = resultado.get("titulares", [])
    titulares_info_en = resultado.get("titulares_en", [])
    resumen_texto = resultado.get("resumen", "")

    if not resumen_texto:
        archivo_resumen = os.path.join("resumenes", f"resumen_{fecha_str}.txt")
        if os.path.exists(archivo_resumen):
            with open(archivo_resumen, "r", encoding="utf-8") as f:
                resumen_texto = f.read()

    # ‚òÅÔ∏è Nube
    archivo_nube = os.path.join("nubes", f"nube_{fecha_str}.png")

    # üìä Indicadores econ√≥micos
    fecha_dt = pd.to_datetime(fecha_str).date()
    economia_dia = df_economia[df_economia["Fecha"] == fecha_dt].copy()
    if "Inflaci√≥n EE.UU." in economia_dia.columns and economia_dia["Inflaci√≥n EE.UU."].isnull().all():
        inflacion_usa_reciente = df_economia["Inflaci√≥n EE.UU."].dropna().iloc[-1]
        economia_dia["Inflaci√≥n EE.UU."] = inflacion_usa_reciente
    
    if not economia_dia.empty:
        df_formateada = economia_dia.copy()

        # Columnas en d√≥lares
        cols_dolar = ["Tipo de Cambio FIX", "Nivel m√°ximo", "Nivel m√≠nimo"]
        for col in cols_dolar:
            if col in df_formateada.columns:
                df_formateada[col] = df_formateada[col].apply(lambda x: f"${x:,.2f}" if pd.notnull(x) else "")

        # Columnas en porcentaje
        cols_porcentaje = [
            "Tasa de Inter√©s Objetivo", "TIIE 28 d√≠as", "TIIE 91 d√≠as", "TIIE 182 d√≠as",
            "SOFR", "Inflaci√≥n EE.UU.", "Inflaci√≥n M√©xico",
            "% Dow Jones", "% S&P500", "% Nasdaq"
        ]
        for col in cols_porcentaje:
            if col in df_formateada.columns:
                df_formateada[col] = df_formateada[col].apply(lambda x: f"{x*100:.2f}%" if pd.notnull(x) else "")

        economia_dict = OrderedDict()
        for col in df_formateada.columns[1:]:
            economia_dict[col] = df_formateada.iloc[0][col]

        # üîπ Construcci√≥n manual en 3 filas fijas
        filas = [
            ["Tipo de Cambio FIX", "Nivel m√°ximo", "Nivel m√≠nimo"],
            ["Tasa de Inter√©s Objetivo", "TIIE 28 d√≠as", "TIIE 91 d√≠as", "TIIE 182 d√≠as"],
            ["SOFR", "% Dow Jones", "% S&P500", "% Nasdaq"],
            ["Inflaci√≥n M√©xico", "Inflaci√≥n EE.UU."]
        ]

        indicadores_html = ""
        for fila in filas:
            indicadores_html += "<div style='display:flex; flex-wrap:wrap; gap:12px; margin-top:10px;'>"
            for col in fila:
                valor = economia_dict.get(col, "")
                indicadores_html += f"""
                <div style="flex:1 1 calc(25% - 12px); background:#fff; border:1px solid #ddd; border-radius:12px; padding:12px; text-align:center; min-width:150px;">
                    <div style="font-size:0.85rem; color:#7D7B78; margin-bottom:6px;">{col}</div>
                    <div style="font-size:1.1rem; font-weight:700; color:#111;">{valor}</div>
                </div>
                """
            indicadores_html += "</div>"
    else:
        indicadores_html = "<p>No hay datos econ√≥micos</p>"



    # ---- CONFIGURACI√ìN DEL CORREO ----
    remitente = "ldsantiagovidargas.93@gmail.com"
    password = os.environ.get("GMAIL_PASSWORD_APP")
    destinatario = email

    msg = MIMEMultipart()
    msg["From"] = remitente
    msg["To"] = destinatario
    msg["Subject"] = f"Resumen de noticias {fecha_str}"


    # üìß Plantilla HTML con estilo
    cuerpo = f"""
    
    <table role="presentation" cellspacing="0" cellpadding="0" border="0" align="center" style="width:100%; max-width:800px; font-family:Montserrat,Arial,sans-serif; border-collapse:collapse; margin:auto;">
    <!-- Header con fondo blanco -->
    <tr>
        <td style="background:#fff; padding:16px 20px; border-bottom:2px solid #e5e7eb;">
        <table role="presentation" cellspacing="0" cellpadding="0" border="0" width="100%">
            <tr>
            <td align="left">
                <img src="cid:logo" alt="Cliente" style="height:40px;">
            </td>
            <td align="right" style="font-weight:700; font-size:1.2rem; color:#111;">
                Monitoreo<span style="color:#FFB429;">+</span>
            </td>
            </tr>
        </table>
        </td>
    </tr>

    <!-- Bloque gris con contenido -->
    <tr>
        <td style="background:#f9f9f9; padding:20px; border:1px solid #e5e7eb; border-radius:0 0 12px 12px;">
        
        <!-- Resumen -->
        <h2 style="font-size:1.4rem; font-weight:700; margin-bottom:14px; color:#111;">
            üìÖ Resumen diario de noticias ‚Äî {fecha_str}
        </h2>
        <div style="background:#fff; border:1px solid #ddd; border-radius:12px; padding:20px; margin-bottom:20px;">
            <p style="color:#555; line-height:1.7; text-align:justify;">{resumen_texto}</p>
        </div>

        <!-- Indicadores -->
        <h3 style="font-size:1.15rem; font-weight:700; color:#555; margin-top:20px;">üìä Indicadores econ√≥micos</h3>
        {indicadores_html}

        <!-- Titulares espa√±ol -->
        <h3 style="font-size:1.15rem; font-weight:700; color:#555; margin-top:20px;">üóûÔ∏è Principales titulares en espa√±ol</h3>
        <div style="display:flex; flex-direction:column; gap:8px; margin-bottom:20px;">
            {''.join([f"<div style='padding:10px; border:1px solid #ddd; border-radius:12px; background:#fff; max-width:100%; word-break:normal; white-space:normal; overflow-wrap:anywhere;'><a href='{t['enlace']}' style='color:#0B57D0; font-weight:600; text-decoration:none;'>{t['titulo']}</a><br><small style='color:#7D7B78;'>‚Ä¢ {t['medio']}</small></div>" for t in titulares_info if t.get('idioma','es')=='es'])}
        </div>

        <!-- Titulares ingl√©s -->
        <h3 style="font-size:1.15rem; font-weight:700; color:#555; margin-top:20px;">üóûÔ∏è Principales titulares en ingl√©s</h3>
        <div style="display:flex; flex-direction:column; gap:8px; margin-bottom:20px;">
            {''.join([f"<div style='padding:10px; border:1px solid #ddd; border-radius:12px; background:#fff; max-width:100%; word-break:normal; white-space:normal; overflow-wrap:anywhere;'><a href='{t['enlace']}' style='color:#0B57D0; font-weight:600; text-decoration:none;'>{t['titulo']}</a><br><small style='color:#7D7B78;'>‚Ä¢ {t['medio']}</small></div>" for t in titulares_info_en])}
        </div>

        <!-- Nube -->
        <h3 style="font-size:1.15rem; font-weight:700; color:#555; margin-top:20px;">‚òÅÔ∏è Nube de palabras</h3>
        <div style="text-align:center; margin-top:12px;">
            <img src="cid:nube" alt="Nube de palabras" style="width:100%; max-width:600px; border-radius:12px; border:1px solid #ddd;" />
        </div>

        </td>
    </tr>
    </table>
    """


    msg.attach(MIMEText(cuerpo, "html"))

    # üìé Adjuntar nube inline
    if os.path.exists(archivo_nube):
        with open(archivo_nube, "rb") as img_file:
            imagen = MIMEImage(img_file.read())
            imagen.add_header("Content-ID", "<nube>")
            imagen.add_header("Content-Disposition", "inline", filename=archivo_nube)
            msg.attach(imagen)

    # üìé Adjuntar logo del cliente inline
    if os.path.exists("logo.png"):  # aseg√∫rate de poner el logo en tu carpeta del proyecto
        with open("logo.png", "rb") as logo_file:
            logo = MIMEImage(logo_file.read())
            logo.add_header("Content-ID", "<logo>")
            logo.add_header("Content-Disposition", "inline", filename="logo.png")
            msg.attach(logo)        

    try:
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(remitente, password)
        server.sendmail(remitente, destinatario, msg.as_string())
        server.quit()
        return jsonify({"mensaje": f"‚úÖ Correo enviado a {destinatario}"})
    except Exception as e:
        return jsonify({"mensaje": f"‚ùå Error al enviar correo: {e}"})

@app.route("/nube/<filename>")
def serve_nube(filename):
    return send_from_directory("nubes", filename)

@app.route("/fechas")
def get_fechas():
    # Obtener todas las fechas √∫nicas, ordenadas de m√°s reciente a m√°s antigua
    fechas_unicas = sorted(df["Fecha"].dt.date.unique(), reverse=True)
    fechas_str = [f.strftime("%Y-%m-%d") for f in fechas_unicas]
    return jsonify(fechas_str)

# ------------------------------
# üìë Endpoint para an√°lisis semanal
# ------------------------------
@app.route("/an√°lisis_semanal", methods=["GET"])
def analisis_semanal():
    carpeta = "an√°lisis_semanal"
    os.makedirs(carpeta, exist_ok=True)

    archivos = [
        f for f in os.listdir(carpeta)
        if f.lower().endswith(".pdf")
    ]
    archivos.sort(reverse=True)  # m√°s recientes primero

    resultados = []
    for f in archivos:
        # Extraer fechas del nombre (ej: analisis_2025-08-25_a_2025-08-29.pdf)
        match = re.search(r"(\d{4}-\d{2}-\d{2})_a_(\d{4}-\d{2}-\d{2})", f)
        if match:
            fecha_inicio = datetime.strptime(match.group(1), "%Y-%m-%d")
            fecha_fin = datetime.strptime(match.group(2), "%Y-%m-%d")
            nombre_bonito = f"An√°lisis semanal: {fecha_inicio.day}‚Äì{fecha_fin.day} {nombre_mes(fecha_fin)}"
        else:
            nombre_bonito = f  # fallback al nombre del archivo

        resultados.append({
            "nombre": nombre_bonito,
            "url": f"/an√°lisis/{f}"
        })

    return jsonify(resultados)

@app.route("/analisis/<path:filename>", methods=["GET"])
def descargar_analisis(filename):
    return send_from_directory("an√°lisis_semanal", filename, as_attachment=False)


if __name__ == "__main__":
    import os
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
